<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Canonical Correlation Analysis (CCA) | DS 6388 Spring 2025</title>
  <meta name="description" content="7 Canonical Correlation Analysis (CCA) | DS 6388 Spring 2025" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Canonical Correlation Analysis (CCA) | DS 6388 Spring 2025" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Canonical Correlation Analysis (CCA) | DS 6388 Spring 2025" />
  
  
  

<meta name="author" content="Rene Gutierrez University of Texas at El Paso" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="factor-analysis.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> DS 6388: Multivariate Statistical Methods for High-dimensional Data</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#calendar"><i class="fa fa-check"></i><b>1.1</b> Calendar</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#importatnt-dates"><i class="fa fa-check"></i><b>1.1.1</b> Importatnt Dates</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#class-schedule"><i class="fa fa-check"></i><b>1.1.2</b> Class Schedule</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="2.1" data-path="prerequisites.html"><a href="prerequisites.html#linear-algebra"><i class="fa fa-check"></i><b>2.1</b> Linear Algebra</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="prerequisites.html"><a href="prerequisites.html#linear-independence"><i class="fa fa-check"></i><b>2.1.1</b> Linear Independence</a></li>
<li class="chapter" data-level="2.1.2" data-path="prerequisites.html"><a href="prerequisites.html#column-space-of-a-matrix"><i class="fa fa-check"></i><b>2.1.2</b> Column Space of a Matrix</a></li>
<li class="chapter" data-level="2.1.3" data-path="prerequisites.html"><a href="prerequisites.html#rank-of-a-matrix"><i class="fa fa-check"></i><b>2.1.3</b> Rank of a Matrix</a></li>
<li class="chapter" data-level="2.1.4" data-path="prerequisites.html"><a href="prerequisites.html#full-rank-matrix"><i class="fa fa-check"></i><b>2.1.4</b> Full Rank Matrix</a></li>
<li class="chapter" data-level="2.1.5" data-path="prerequisites.html"><a href="prerequisites.html#inverse-matrix"><i class="fa fa-check"></i><b>2.1.5</b> Inverse Matrix</a></li>
<li class="chapter" data-level="2.1.6" data-path="prerequisites.html"><a href="prerequisites.html#positive-definite-matrix"><i class="fa fa-check"></i><b>2.1.6</b> Positive Definite Matrix</a></li>
<li class="chapter" data-level="2.1.7" data-path="prerequisites.html"><a href="prerequisites.html#singular-value-decomposition"><i class="fa fa-check"></i><b>2.1.7</b> Singular Value Decomposition</a></li>
<li class="chapter" data-level="2.1.8" data-path="prerequisites.html"><a href="prerequisites.html#eigendecomposition"><i class="fa fa-check"></i><b>2.1.8</b> Eigendecomposition</a></li>
<li class="chapter" data-level="2.1.9" data-path="prerequisites.html"><a href="prerequisites.html#idempotent-matrix"><i class="fa fa-check"></i><b>2.1.9</b> Idempotent Matrix</a></li>
<li class="chapter" data-level="2.1.10" data-path="prerequisites.html"><a href="prerequisites.html#determinant-of-a-matrix"><i class="fa fa-check"></i><b>2.1.10</b> Determinant of a Matrix</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="prerequisites.html"><a href="prerequisites.html#calculus"><i class="fa fa-check"></i><b>2.2</b> Calculus</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="prerequisites.html"><a href="prerequisites.html#gradient"><i class="fa fa-check"></i><b>2.2.1</b> Gradient</a></li>
<li class="chapter" data-level="2.2.2" data-path="prerequisites.html"><a href="prerequisites.html#hessian-matrix"><i class="fa fa-check"></i><b>2.2.2</b> Hessian Matrix</a></li>
<li class="chapter" data-level="2.2.3" data-path="prerequisites.html"><a href="prerequisites.html#applications-1"><i class="fa fa-check"></i><b>2.2.3</b> Applications:</a></li>
<li class="chapter" data-level="2.2.4" data-path="prerequisites.html"><a href="prerequisites.html#matrix-calculus"><i class="fa fa-check"></i><b>2.2.4</b> Matrix Calculus</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="prerequisites.html"><a href="prerequisites.html#probability"><i class="fa fa-check"></i><b>2.3</b> Probability</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="prerequisites.html"><a href="prerequisites.html#expected-value"><i class="fa fa-check"></i><b>2.3.1</b> Expected Value</a></li>
<li class="chapter" data-level="2.3.2" data-path="prerequisites.html"><a href="prerequisites.html#variance"><i class="fa fa-check"></i><b>2.3.2</b> Variance</a></li>
<li class="chapter" data-level="2.3.3" data-path="prerequisites.html"><a href="prerequisites.html#cross-covariance-matrix"><i class="fa fa-check"></i><b>2.3.3</b> Cross-Covariance Matrix</a></li>
<li class="chapter" data-level="2.3.4" data-path="prerequisites.html"><a href="prerequisites.html#multivariate-normal-distribution"><i class="fa fa-check"></i><b>2.3.4</b> Multivariate Normal Distribution</a></li>
<li class="chapter" data-level="2.3.5" data-path="prerequisites.html"><a href="prerequisites.html#chi2-distribution"><i class="fa fa-check"></i><b>2.3.5</b> <span class="math inline">\(\chi^2\)</span> Distribution</a></li>
<li class="chapter" data-level="2.3.6" data-path="prerequisites.html"><a href="prerequisites.html#t-distribution"><i class="fa fa-check"></i><b>2.3.6</b> <span class="math inline">\(t\)</span> Distribution</a></li>
<li class="chapter" data-level="2.3.7" data-path="prerequisites.html"><a href="prerequisites.html#f-distribution"><i class="fa fa-check"></i><b>2.3.7</b> <span class="math inline">\(F\)</span> Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="prerequisites.html"><a href="prerequisites.html#statistics"><i class="fa fa-check"></i><b>2.4</b> Statistics</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="prerequisites.html"><a href="prerequisites.html#bias-of-an-estimator"><i class="fa fa-check"></i><b>2.4.1</b> Bias of an Estimator</a></li>
<li class="chapter" data-level="2.4.2" data-path="prerequisites.html"><a href="prerequisites.html#unbiased-estimator"><i class="fa fa-check"></i><b>2.4.2</b> Unbiased Estimator</a></li>
<li class="chapter" data-level="2.4.3" data-path="prerequisites.html"><a href="prerequisites.html#mean-square-error-of-an-estimator"><i class="fa fa-check"></i><b>2.4.3</b> Mean Square Error of an Estimator</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>3</b> Introduction</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction.html"><a href="introduction.html#key-challenges"><i class="fa fa-check"></i><b>3.1</b> Key Challenges</a></li>
<li class="chapter" data-level="3.2" data-path="introduction.html"><a href="introduction.html#core-concepts"><i class="fa fa-check"></i><b>3.2</b> Core Concepts</a></li>
<li class="chapter" data-level="3.3" data-path="introduction.html"><a href="introduction.html#applications-4"><i class="fa fa-check"></i><b>3.3</b> Applications</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>4</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="linear-regression.html"><a href="linear-regression.html#machine-learning"><i class="fa fa-check"></i><b>4.1</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="linear-regression.html"><a href="linear-regression.html#ordinary-least-squares"><i class="fa fa-check"></i><b>4.1.1</b> Ordinary Least Squares</a></li>
<li class="chapter" data-level="4.1.2" data-path="linear-regression.html"><a href="linear-regression.html#ridge-regression"><i class="fa fa-check"></i><b>4.1.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="4.1.3" data-path="linear-regression.html"><a href="linear-regression.html#lasso-regression"><i class="fa fa-check"></i><b>4.1.3</b> Lasso Regression</a></li>
<li class="chapter" data-level="4.1.4" data-path="linear-regression.html"><a href="linear-regression.html#elastic-net"><i class="fa fa-check"></i><b>4.1.4</b> Elastic Net</a></li>
<li class="chapter" data-level="4.1.5" data-path="linear-regression.html"><a href="linear-regression.html#elastic-net-as-a-mixed-penalty"><i class="fa fa-check"></i><b>4.1.5</b> <strong>Elastic Net as a Mixed Penalty</strong></a></li>
<li class="chapter" data-level="4.1.6" data-path="linear-regression.html"><a href="linear-regression.html#other-options-of-regularization"><i class="fa fa-check"></i><b>4.1.6</b> Other Options of Regularization</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-linear-regression"><i class="fa fa-check"></i><b>4.2</b> Bayesian Linear Regression</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="linear-regression.html"><a href="linear-regression.html#basic-bayesian-linear-regression"><i class="fa fa-check"></i><b>4.2.1</b> Basic Bayesian Linear Regression</a></li>
<li class="chapter" data-level="4.2.2" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-lasso-regression"><i class="fa fa-check"></i><b>4.2.2</b> Bayesian Lasso Regression</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="linear-regression.html"><a href="linear-regression.html#computational-comparisson"><i class="fa fa-check"></i><b>4.3</b> Computational Comparisson</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="linear-regression.html"><a href="linear-regression.html#set-up"><i class="fa fa-check"></i><b>4.3.1</b> Set-Up</a></li>
<li class="chapter" data-level="4.3.2" data-path="linear-regression.html"><a href="linear-regression.html#simulation"><i class="fa fa-check"></i><b>4.3.2</b> Simulation</a></li>
<li class="chapter" data-level="4.3.3" data-path="linear-regression.html"><a href="linear-regression.html#ols"><i class="fa fa-check"></i><b>4.3.3</b> OLS</a></li>
<li class="chapter" data-level="4.3.4" data-path="linear-regression.html"><a href="linear-regression.html#ridge-regression-1"><i class="fa fa-check"></i><b>4.3.4</b> Ridge Regression</a></li>
<li class="chapter" data-level="4.3.5" data-path="linear-regression.html"><a href="linear-regression.html#lasso"><i class="fa fa-check"></i><b>4.3.5</b> Lasso</a></li>
<li class="chapter" data-level="4.3.6" data-path="linear-regression.html"><a href="linear-regression.html#basic-bayesian-regression"><i class="fa fa-check"></i><b>4.3.6</b> Basic Bayesian Regression</a></li>
<li class="chapter" data-level="4.3.7" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-lasso"><i class="fa fa-check"></i><b>4.3.7</b> Bayesian Lasso</a></li>
<li class="chapter" data-level="4.3.8" data-path="linear-regression.html"><a href="linear-regression.html#bayesian-horseshoe-prior"><i class="fa fa-check"></i><b>4.3.8</b> Bayesian Horseshoe Prior</a></li>
<li class="chapter" data-level="4.3.9" data-path="linear-regression.html"><a href="linear-regression.html#results-comparisson"><i class="fa fa-check"></i><b>4.3.9</b> Results Comparisson</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="linear-regression.html"><a href="linear-regression.html#efficient-computation"><i class="fa fa-check"></i><b>4.4</b> Efficient Computation</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="linear-regression.html"><a href="linear-regression.html#efficient-computation-of-ridge-regression-using-the-woodbury-identity"><i class="fa fa-check"></i><b>4.4.1</b> Efficient Computation of Ridge Regression using the Woodbury Identity</a></li>
<li class="chapter" data-level="4.4.2" data-path="linear-regression.html"><a href="linear-regression.html#efficient-bayesian-sampling-for-gaussian-scale-mixture-priors"><i class="fa fa-check"></i><b>4.4.2</b> Efficient Bayesian Sampling for Gaussian Scale-Mixture Priors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>5</b> Principal Component Analysis</a>
<ul>
<li class="chapter" data-level="5.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#pca-as-a-low-rank-approximation-of-mathbfx"><i class="fa fa-check"></i><b>5.1</b> PCA as a Low-Rank Approximation of <span class="math inline">\(\mathbf{X}\)</span></a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#why-low-rank-approximation-matters"><i class="fa fa-check"></i><b>5.1.1</b> Why Low-Rank Approximation Matters</a></li>
<li class="chapter" data-level="5.1.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#the-singular-value-solution-is-the-best-low-rank-approximation-eckartyoungmirsky-theorem"><i class="fa fa-check"></i><b>5.1.2</b> The Singular Value Solution is the Best Low-Rank Approximation (Eckart–Young–Mirsky Theorem)</a></li>
<li class="chapter" data-level="5.1.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#eckartyoungmirsky-theorem-for-the-spectral-norm"><i class="fa fa-check"></i><b>5.1.3</b> Eckart–Young–Mirsky Theorem for the Spectral Norm</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#variance-maximization-in-pca"><i class="fa fa-check"></i><b>5.2</b> Variance Maximization in PCA</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#first-principal-cmponent"><i class="fa fa-check"></i><b>5.2.1</b> First Principal Cmponent</a></li>
<li class="chapter" data-level="5.2.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#second-principal-component"><i class="fa fa-check"></i><b>5.2.2</b> Second Principal Component</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#parafac-decomposition"><i class="fa fa-check"></i><b>5.3</b> PARAFAC decomposition</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#what-is-a-tensor"><i class="fa fa-check"></i><b>5.3.1</b> What is a Tensor?</a></li>
<li class="chapter" data-level="5.3.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#motivation-why-generalize-pca-to-tensors"><i class="fa fa-check"></i><b>5.3.2</b> Motivation: Why Generalize PCA to Tensors?</a></li>
<li class="chapter" data-level="5.3.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#parafac-decomposition-definition"><i class="fa fa-check"></i><b>5.3.3</b> PARAFAC Decomposition Definition</a></li>
<li class="chapter" data-level="5.3.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#how-is-parafac-related-to-pca"><i class="fa fa-check"></i><b>5.3.4</b> How is PARAFAC Related to PCA?</a></li>
<li class="chapter" data-level="5.3.5" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#key-properties-of-parafac-decomposition"><i class="fa fa-check"></i><b>5.3.5</b> Key Properties of PARAFAC Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#high-dimensional-pca"><i class="fa fa-check"></i><b>5.4</b> High-Dimensional PCA</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#high-dimensional-pca-p-gg-n"><i class="fa fa-check"></i><b>5.4.1</b> High-Dimensional PCA (<span class="math inline">\(p \gg n\)</span>)</a></li>
<li class="chapter" data-level="5.4.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#randomized-pca"><i class="fa fa-check"></i><b>5.4.2</b> Randomized PCA</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#principal-components-regression"><i class="fa fa-check"></i><b>5.5</b> Principal Components Regression</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#what-is-principal-components-regression"><i class="fa fa-check"></i><b>5.5.1</b> What is Principal Components Regression?</a></li>
<li class="chapter" data-level="5.5.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#why-use-pcr"><i class="fa fa-check"></i><b>5.5.2</b> Why Use PCR?</a></li>
<li class="chapter" data-level="5.5.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#mathematical-formulation"><i class="fa fa-check"></i><b>5.5.3</b> Mathematical Formulation</a></li>
<li class="chapter" data-level="5.5.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#choosing-the-number-of-components"><i class="fa fa-check"></i><b>5.5.4</b> Choosing the Number of Components</a></li>
<li class="chapter" data-level="5.5.5" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#advantages-of-pcr"><i class="fa fa-check"></i><b>5.5.5</b> Advantages of PCR</a></li>
<li class="chapter" data-level="5.5.6" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#disadvantages"><i class="fa fa-check"></i><b>5.5.6</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.7" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#randomized-pca-and-pcr"><i class="fa fa-check"></i><b>5.5.7</b> Randomized PCA and PCR</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>6</b> Factor Analysis</a>
<ul>
<li class="chapter" data-level="6.1" data-path="factor-analysis.html"><a href="factor-analysis.html#introduction-2"><i class="fa fa-check"></i><b>6.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="factor-analysis.html"><a href="factor-analysis.html#how-factor-analysis-works"><i class="fa fa-check"></i><b>6.1.1</b> How Factor Analysis Works</a></li>
<li class="chapter" data-level="6.1.2" data-path="factor-analysis.html"><a href="factor-analysis.html#why-is-factor-analysis-useful"><i class="fa fa-check"></i><b>6.1.2</b> Why is Factor Analysis Useful?</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="factor-analysis.html"><a href="factor-analysis.html#factor-analysis-model"><i class="fa fa-check"></i><b>6.2</b> Factor Analysis Model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="factor-analysis.html"><a href="factor-analysis.html#model-specification-1"><i class="fa fa-check"></i><b>6.2.1</b> Model Specification</a></li>
<li class="chapter" data-level="6.2.2" data-path="factor-analysis.html"><a href="factor-analysis.html#assumptions"><i class="fa fa-check"></i><b>6.2.2</b> Assumptions</a></li>
<li class="chapter" data-level="6.2.3" data-path="factor-analysis.html"><a href="factor-analysis.html#variance-covariance-matrix"><i class="fa fa-check"></i><b>6.2.3</b> Variance-Covariance Matrix</a></li>
<li class="chapter" data-level="6.2.4" data-path="factor-analysis.html"><a href="factor-analysis.html#implications"><i class="fa fa-check"></i><b>6.2.4</b> Implications</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="factor-analysis.html"><a href="factor-analysis.html#estimation-in-factor-analysis"><i class="fa fa-check"></i><b>6.3</b> Estimation in Factor Analysis</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="factor-analysis.html"><a href="factor-analysis.html#principal-components-method"><i class="fa fa-check"></i><b>6.3.1</b> Principal Components Method</a></li>
<li class="chapter" data-level="6.3.2" data-path="factor-analysis.html"><a href="factor-analysis.html#principal-factor-method"><i class="fa fa-check"></i><b>6.3.2</b> Principal Factor Method</a></li>
<li class="chapter" data-level="6.3.3" data-path="factor-analysis.html"><a href="factor-analysis.html#maximum-likelihood-estimation-mle"><i class="fa fa-check"></i><b>6.3.3</b> Maximum Likelihood Estimation (MLE)</a></li>
<li class="chapter" data-level="6.3.4" data-path="factor-analysis.html"><a href="factor-analysis.html#bayesian-estimation-hierarchical-priors"><i class="fa fa-check"></i><b>6.3.4</b> Bayesian Estimation (Hierarchical Priors)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="factor-analysis.html"><a href="factor-analysis.html#estimating-factor-scores-in-factor-analysis"><i class="fa fa-check"></i><b>6.4</b> Estimating Factor Scores in Factor Analysis</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="factor-analysis.html"><a href="factor-analysis.html#ordinary-least-squares-ols-method"><i class="fa fa-check"></i><b>6.4.1</b> Ordinary Least Squares (OLS) Method</a></li>
<li class="chapter" data-level="6.4.2" data-path="factor-analysis.html"><a href="factor-analysis.html#weighted-least-squares-wls-method-bartletts-method"><i class="fa fa-check"></i><b>6.4.2</b> Weighted Least Squares (WLS) Method (Bartlett’s Method)</a></li>
<li class="chapter" data-level="6.4.3" data-path="factor-analysis.html"><a href="factor-analysis.html#regression-method-thompsons-estimator"><i class="fa fa-check"></i><b>6.4.3</b> Regression Method (Thompson’s Estimator)</a></li>
<li class="chapter" data-level="6.4.4" data-path="factor-analysis.html"><a href="factor-analysis.html#summary-of-factor-score-estimators"><i class="fa fa-check"></i><b>6.4.4</b> Summary of Factor Score Estimators</a></li>
<li class="chapter" data-level="6.4.5" data-path="factor-analysis.html"><a href="factor-analysis.html#key-takeaways"><i class="fa fa-check"></i><b>6.4.5</b> Key Takeaways</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="factor-analysis.html"><a href="factor-analysis.html#factor-analysis-example"><i class="fa fa-check"></i><b>6.5</b> Factor Analysis Example</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="factor-analysis.html"><a href="factor-analysis.html#load-required-libraries"><i class="fa fa-check"></i><b>6.5.1</b> Load Required Libraries</a></li>
<li class="chapter" data-level="6.5.2" data-path="factor-analysis.html"><a href="factor-analysis.html#generate-sample-data"><i class="fa fa-check"></i><b>6.5.2</b> Generate Sample Data</a></li>
<li class="chapter" data-level="6.5.3" data-path="factor-analysis.html"><a href="factor-analysis.html#estimation-of-factor-loadings-and-unique-variances"><i class="fa fa-check"></i><b>6.5.3</b> Estimation of Factor Loadings and Unique Variances</a></li>
<li class="chapter" data-level="6.5.4" data-path="factor-analysis.html"><a href="factor-analysis.html#estimate-factor-scores"><i class="fa fa-check"></i><b>6.5.4</b> Estimate Factor Scores</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html"><i class="fa fa-check"></i><b>7</b> Canonical Correlation Analysis (CCA)</a>
<ul>
<li class="chapter" data-level="7.1" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#motivation-1"><i class="fa fa-check"></i><b>7.1</b> Motivation</a></li>
<li class="chapter" data-level="7.2" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#mathematical-formulation-1"><i class="fa fa-check"></i><b>7.2</b> Mathematical Formulation</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#key-properties-6"><i class="fa fa-check"></i><b>7.2.1</b> Key Properties</a></li>
<li class="chapter" data-level="7.2.2" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#implementation-in-r"><i class="fa fa-check"></i><b>7.2.2</b> Implementation in R</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#canonical-directions-estimation"><i class="fa fa-check"></i><b>7.3</b> Canonical Directions Estimation</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#problem-definition-with-random-variables"><i class="fa fa-check"></i><b>7.3.1</b> Problem Definition with Random Variables</a></li>
<li class="chapter" data-level="7.3.2" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#canonical-correlation-maximization-problem"><i class="fa fa-check"></i><b>7.3.2</b> Canonical Correlation Maximization Problem</a></li>
<li class="chapter" data-level="7.3.3" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#solving-for-the-canonical-directions-using-lagrange-multipliers"><i class="fa fa-check"></i><b>7.3.3</b> Solving for the Canonical Directions Using Lagrange Multipliers</a></li>
<li class="chapter" data-level="7.3.4" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#showing-that-the-matrices-have-the-same-eigenvalues"><i class="fa fa-check"></i><b>7.3.4</b> Showing That the Matrices Have the Same Eigenvalues</a></li>
<li class="chapter" data-level="7.3.5" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#showing-that-the-largest-eigenvalue-maximizes-the-objective-function"><i class="fa fa-check"></i><b>7.3.5</b> Showing That the Largest Eigenvalue Maximizes the Objective Function</a></li>
<li class="chapter" data-level="7.3.6" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#conclusion-3"><i class="fa fa-check"></i><b>7.3.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#hd-cca"><i class="fa fa-check"></i><b>7.4</b> HD CCA</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#regularized-canonical-correlation-analysis-ridge-cca"><i class="fa fa-check"></i><b>7.4.1</b> Regularized Canonical Correlation Analysis (Ridge CCA)</a></li>
<li class="chapter" data-level="7.4.2" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#sparse-canonical-correlation-analysis-sparse-cca"><i class="fa fa-check"></i><b>7.4.2</b> Sparse Canonical Correlation Analysis (Sparse CCA)**</a></li>
<li class="chapter" data-level="7.4.3" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#low-rank-approximation-cca-randomized-svd-approach"><i class="fa fa-check"></i><b>7.4.3</b> Low-Rank Approximation CCA (Randomized SVD Approach)</a></li>
<li class="chapter" data-level="7.4.4" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#factor-model-based-cca"><i class="fa fa-check"></i><b>7.4.4</b> Factor Model-Based CCA</a></li>
<li class="chapter" data-level="7.4.5" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#comparison-of-methods-for-high-dimensional-cca"><i class="fa fa-check"></i><b>7.4.5</b> Comparison of Methods for High-Dimensional CCA</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="canonical-correlation-analysis-cca.html"><a href="canonical-correlation-analysis-cca.html#conclusion-which-method-to-use"><i class="fa fa-check"></i><b>7.5</b> <strong>Conclusion: Which Method to Use?</strong></a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DS 6388 Spring 2025</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="canonical-correlation-analysis-cca" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">7</span> Canonical Correlation Analysis (CCA)<a href="canonical-correlation-analysis-cca.html#canonical-correlation-analysis-cca" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Canonical Correlation Analysis (<strong>CCA</strong>) is a <strong>multivariate statistical method</strong> used to study the relationships between two sets of variables. It generalizes correlation by finding <strong>pairs of linear combinations</strong> (called <strong>canonical variables</strong>) that maximize the correlation between the two datasets.</p>
<hr />
<div id="motivation-1" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Motivation<a href="canonical-correlation-analysis-cca.html#motivation-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Imagine you have <strong>two sets of related variables</strong>:<br />
- <strong>Set 1 (e.g., Psychological traits)</strong> → <span class="math inline">\(\mathbf{X}\)</span> (e.g., intelligence, memory, reasoning)<br />
- <strong>Set 2 (e.g., Academic performance)</strong> → <span class="math inline">\(\mathbf{Y}\)</span> (e.g., math scores, reading scores, writing scores)</p>
<p>Standard correlation measures relationships <strong>between individual variables</strong> (e.g., intelligence vs. math score).<br />
CCA, however, finds <strong>pairs of linear combinations</strong> that <strong>maximize the correlation</strong> between the two sets.</p>
<hr />
</div>
<div id="mathematical-formulation-1" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Mathematical Formulation<a href="canonical-correlation-analysis-cca.html#mathematical-formulation-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Given:
- <span class="math inline">\(\mathbf{X}\)</span> (a matrix of size <span class="math inline">\(n \times p\)</span>) representing <strong><span class="math inline">\(p\)</span> variables</strong>.
- <span class="math inline">\(\mathbf{Y}\)</span> (a matrix of size <span class="math inline">\(n \times q\)</span>) representing <strong><span class="math inline">\(q\)</span> variables</strong>.</p>
<p>CCA finds weight vectors <span class="math inline">\(\mathbf{a}\)</span> and <span class="math inline">\(\mathbf{b}\)</span> such that the linear combinations:</p>
<p><span class="math display">\[
U = \mathbf{X} \mathbf{a}, \quad V = \mathbf{Y} \mathbf{b}
\]</span></p>
<p>maximize the correlation:</p>
<p><span class="math display">\[
\rho = \frac{\mathbb{C}[U, V]}{\sqrt{\mathbb{V}[U] \mathbb{V}[V]}}.
\]</span></p>
<p>where:
- <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> are called <strong>canonical variables</strong>.
- <span class="math inline">\(\rho\)</span> is the <strong>canonical correlation</strong>.</p>
<hr />
<div id="key-properties-6" class="section level3 hasAnchor" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Key Properties<a href="canonical-correlation-analysis-cca.html#key-properties-6" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>*Finds relationships between two sets of variables**, beyond individual correlations.<br />
</li>
<li>*Can extract multiple pairs** of canonical variables, each pair capturing a different aspect of the relationship.<br />
</li>
<li>*Works even when the number of variables in <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span> are different**.</li>
</ul>
<hr />
</div>
<div id="implementation-in-r" class="section level3 hasAnchor" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Implementation in R<a href="canonical-correlation-analysis-cca.html#implementation-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can perform <strong>Canonical Correlation Analysis (CCA)</strong> in R using the <code>cancor()</code> function.</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="canonical-correlation-analysis-cca.html#cb132-1" tabindex="-1"></a><span class="co"># Load dataset</span></span>
<span id="cb132-2"><a href="canonical-correlation-analysis-cca.html#cb132-2" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;iris&quot;</span>)</span>
<span id="cb132-3"><a href="canonical-correlation-analysis-cca.html#cb132-3" tabindex="-1"></a></span>
<span id="cb132-4"><a href="canonical-correlation-analysis-cca.html#cb132-4" tabindex="-1"></a><span class="co"># Define two variable sets</span></span>
<span id="cb132-5"><a href="canonical-correlation-analysis-cca.html#cb132-5" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(iris[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])  <span class="co"># Sepal Length and Sepal Width</span></span>
<span id="cb132-6"><a href="canonical-correlation-analysis-cca.html#cb132-6" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(iris[, <span class="dv">3</span><span class="sc">:</span><span class="dv">4</span>])  <span class="co"># Petal Length and Petal Width</span></span>
<span id="cb132-7"><a href="canonical-correlation-analysis-cca.html#cb132-7" tabindex="-1"></a></span>
<span id="cb132-8"><a href="canonical-correlation-analysis-cca.html#cb132-8" tabindex="-1"></a><span class="co"># Perform CCA</span></span>
<span id="cb132-9"><a href="canonical-correlation-analysis-cca.html#cb132-9" tabindex="-1"></a>cca_result <span class="ot">&lt;-</span> <span class="fu">cancor</span>(X, Y)</span>
<span id="cb132-10"><a href="canonical-correlation-analysis-cca.html#cb132-10" tabindex="-1"></a></span>
<span id="cb132-11"><a href="canonical-correlation-analysis-cca.html#cb132-11" tabindex="-1"></a><span class="co"># Print canonical correlations</span></span>
<span id="cb132-12"><a href="canonical-correlation-analysis-cca.html#cb132-12" tabindex="-1"></a><span class="fu">print</span>(cca_result<span class="sc">$</span>cor)</span></code></pre></div>
<pre><code>## [1] 0.9409690 0.1239369</code></pre>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="canonical-correlation-analysis-cca.html#cb134-1" tabindex="-1"></a><span class="co"># Print canonical weight vectors</span></span>
<span id="cb134-2"><a href="canonical-correlation-analysis-cca.html#cb134-2" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Canonical Weights for X:&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Canonical Weights for X:&quot;</code></pre>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="canonical-correlation-analysis-cca.html#cb136-1" tabindex="-1"></a><span class="fu">print</span>(cca_result<span class="sc">$</span>xcoef)</span></code></pre></div>
<pre><code>##                     [,1]       [,2]
## Sepal.Length -0.08757435 0.04749411
## Sepal.Width   0.07004363 0.17582970</code></pre>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="canonical-correlation-analysis-cca.html#cb138-1" tabindex="-1"></a><span class="fu">print</span>(<span class="st">&quot;Canonical Weights for Y:&quot;</span>)</span></code></pre></div>
<pre><code>## [1] &quot;Canonical Weights for Y:&quot;</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="canonical-correlation-analysis-cca.html#cb140-1" tabindex="-1"></a><span class="fu">print</span>(cca_result<span class="sc">$</span>ycoef)</span></code></pre></div>
<pre><code>##                     [,1]       [,2]
## Petal.Length -0.06956302 -0.1571867
## Petal.Width   0.05683849  0.3940121</code></pre>
<hr />
<div id="interpreting-the-results" class="section level4 hasAnchor" number="7.2.2.1">
<h4><span class="header-section-number">7.2.2.1</span> Interpreting the Results<a href="canonical-correlation-analysis-cca.html#interpreting-the-results" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><strong>Canonical Correlations (<code>cca_result$cor</code>)</strong>
<ul>
<li>These are the highest correlations between <strong>linear combinations</strong> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.<br />
</li>
<li>If high (close to 1), the datasets are strongly related.</li>
</ul></li>
<li><strong>Canonical Coefficients (<code>cca_result$xcoef</code> and <code>cca_result$ycoef</code>)</strong>
<ul>
<li>These tell us <strong>how each original variable contributes</strong> to the <strong>canonical variables</strong>.<br />
</li>
<li>Larger absolute values indicate <strong>stronger contributions</strong>.</li>
</ul></li>
</ol>
<hr />
</div>
<div id="visualizing-canonical-correlation-analysis-cca-results" class="section level4 hasAnchor" number="7.2.2.2">
<h4><span class="header-section-number">7.2.2.2</span> Visualizing Canonical Correlation Analysis (CCA) Results<a href="canonical-correlation-analysis-cca.html#visualizing-canonical-correlation-analysis-cca-results" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To better understand <strong>Canonical Correlation Analysis (CCA)</strong>, we can use <strong>scatter plots</strong> and <strong>biplots</strong> to visualize the relationships between canonical variables.</p>
<hr />
<div id="scatter-plot-of-canonical-variables" class="section level5 hasAnchor" number="7.2.2.2.1">
<h5><span class="header-section-number">7.2.2.2.1</span> Scatter Plot of Canonical Variables<a href="canonical-correlation-analysis-cca.html#scatter-plot-of-canonical-variables" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>This plot shows the <strong>first pair of canonical variables</strong> <span class="math inline">\(U_1\)</span> and <span class="math inline">\(V_1\)</span>, allowing us to see how well they are correlated.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="canonical-correlation-analysis-cca.html#cb142-1" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb142-2"><a href="canonical-correlation-analysis-cca.html#cb142-2" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;ggplot2&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:psych&#39;:
## 
##     %+%, alpha</code></pre>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="canonical-correlation-analysis-cca.html#cb145-1" tabindex="-1"></a><span class="co"># Compute canonical variables</span></span>
<span id="cb145-2"><a href="canonical-correlation-analysis-cca.html#cb145-2" tabindex="-1"></a>U <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(X) <span class="sc">%*%</span> cca_result<span class="sc">$</span>xcoef[,<span class="dv">1</span>]  <span class="co"># First canonical variable for X</span></span>
<span id="cb145-3"><a href="canonical-correlation-analysis-cca.html#cb145-3" tabindex="-1"></a>V <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(Y) <span class="sc">%*%</span> cca_result<span class="sc">$</span>ycoef[,<span class="dv">1</span>]  <span class="co"># First canonical variable for Y</span></span>
<span id="cb145-4"><a href="canonical-correlation-analysis-cca.html#cb145-4" tabindex="-1"></a></span>
<span id="cb145-5"><a href="canonical-correlation-analysis-cca.html#cb145-5" tabindex="-1"></a><span class="co"># Create data frame for plotting</span></span>
<span id="cb145-6"><a href="canonical-correlation-analysis-cca.html#cb145-6" tabindex="-1"></a>cca_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">U1 =</span> U, <span class="at">V1 =</span> V)</span>
<span id="cb145-7"><a href="canonical-correlation-analysis-cca.html#cb145-7" tabindex="-1"></a></span>
<span id="cb145-8"><a href="canonical-correlation-analysis-cca.html#cb145-8" tabindex="-1"></a><span class="co"># Scatter plot of canonical variables</span></span>
<span id="cb145-9"><a href="canonical-correlation-analysis-cca.html#cb145-9" tabindex="-1"></a><span class="fu">ggplot</span>(cca_df, <span class="fu">aes</span>(<span class="at">x =</span> U1, <span class="at">y =</span> V1)) <span class="sc">+</span></span>
<span id="cb145-10"><a href="canonical-correlation-analysis-cca.html#cb145-10" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">&quot;blue&quot;</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb145-11"><a href="canonical-correlation-analysis-cca.html#cb145-11" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">color =</span> <span class="st">&quot;red&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb145-12"><a href="canonical-correlation-analysis-cca.html#cb145-12" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb145-13"><a href="canonical-correlation-analysis-cca.html#cb145-13" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Scatter Plot of First Canonical Variables&quot;</span>,</span>
<span id="cb145-14"><a href="canonical-correlation-analysis-cca.html#cb145-14" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;Canonical Variable 1 (U1 from X)&quot;</span>, </span>
<span id="cb145-15"><a href="canonical-correlation-analysis-cca.html#cb145-15" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Canonical Variable 1 (V1 from Y)&quot;</span>)</span></code></pre></div>
<pre><code>## `geom_smooth()` using formula = &#39;y ~ x&#39;</code></pre>
<p><img src="_main_files/figure-html/cca-intro-example-vizualization-1.png" width="672" /></p>
<p><strong>Interpretation:</strong></p>
<ul>
<li>If the correlation is strong, the points will align <strong>closely along a line</strong>.<br />
</li>
<li>A weak correlation will show <strong>a dispersed cloud of points</strong>.</li>
</ul>
<hr />
</div>
<div id="biplot-of-canonical-coefficients" class="section level5 hasAnchor" number="7.2.2.2.2">
<h5><span class="header-section-number">7.2.2.2.2</span> Biplot of Canonical Coefficients<a href="canonical-correlation-analysis-cca.html#biplot-of-canonical-coefficients" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A <strong>biplot</strong> shows how the original variables contribute to the <strong>canonical variables</strong>.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="canonical-correlation-analysis-cca.html#cb147-1" tabindex="-1"></a><span class="co"># Extract canonical coefficients for X and Y</span></span>
<span id="cb147-2"><a href="canonical-correlation-analysis-cca.html#cb147-2" tabindex="-1"></a>cca_x <span class="ot">&lt;-</span> cca_result<span class="sc">$</span>xcoef[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]  <span class="co"># First two canonical coefficients for X</span></span>
<span id="cb147-3"><a href="canonical-correlation-analysis-cca.html#cb147-3" tabindex="-1"></a>cca_y <span class="ot">&lt;-</span> cca_result<span class="sc">$</span>ycoef[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]  <span class="co"># First two canonical coefficients for Y</span></span>
<span id="cb147-4"><a href="canonical-correlation-analysis-cca.html#cb147-4" tabindex="-1"></a></span>
<span id="cb147-5"><a href="canonical-correlation-analysis-cca.html#cb147-5" tabindex="-1"></a><span class="co"># Create a data frame for the arrows</span></span>
<span id="cb147-6"><a href="canonical-correlation-analysis-cca.html#cb147-6" tabindex="-1"></a>cca_biplot_arrows <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb147-7"><a href="canonical-correlation-analysis-cca.html#cb147-7" tabindex="-1"></a>  <span class="at">Variable =</span> <span class="fu">c</span>(<span class="fu">rownames</span>(cca_x), <span class="fu">rownames</span>(cca_y)),</span>
<span id="cb147-8"><a href="canonical-correlation-analysis-cca.html#cb147-8" tabindex="-1"></a>  <span class="at">Canonical1 =</span> <span class="fu">c</span>(cca_x[,<span class="dv">1</span>], cca_y[,<span class="dv">1</span>]),</span>
<span id="cb147-9"><a href="canonical-correlation-analysis-cca.html#cb147-9" tabindex="-1"></a>  <span class="at">Canonical2 =</span> <span class="fu">c</span>(cca_x[,<span class="dv">2</span>], cca_y[,<span class="dv">2</span>]),</span>
<span id="cb147-10"><a href="canonical-correlation-analysis-cca.html#cb147-10" tabindex="-1"></a>  <span class="at">Set =</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;X Variables&quot;</span>, <span class="st">&quot;Y Variables&quot;</span>), <span class="fu">c</span>(<span class="fu">nrow</span>(cca_x), <span class="fu">nrow</span>(cca_y)))</span>
<span id="cb147-11"><a href="canonical-correlation-analysis-cca.html#cb147-11" tabindex="-1"></a>)</span>
<span id="cb147-12"><a href="canonical-correlation-analysis-cca.html#cb147-12" tabindex="-1"></a></span>
<span id="cb147-13"><a href="canonical-correlation-analysis-cca.html#cb147-13" tabindex="-1"></a><span class="co"># Create the biplot with arrows</span></span>
<span id="cb147-14"><a href="canonical-correlation-analysis-cca.html#cb147-14" tabindex="-1"></a><span class="fu">ggplot</span>(cca_biplot_arrows, <span class="fu">aes</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">xend =</span> Canonical1, <span class="at">yend =</span> Canonical2, <span class="at">color =</span> Set)) <span class="sc">+</span></span>
<span id="cb147-15"><a href="canonical-correlation-analysis-cca.html#cb147-15" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.2</span>, <span class="st">&quot;inches&quot;</span>)), <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span>  <span class="co"># Draw arrows</span></span>
<span id="cb147-16"><a href="canonical-correlation-analysis-cca.html#cb147-16" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">x =</span> Canonical1, <span class="at">y =</span> Canonical2, <span class="at">label =</span> Variable), <span class="at">vjust =</span> <span class="fl">1.5</span>, <span class="at">hjust =</span> <span class="fl">1.5</span>) <span class="sc">+</span>  <span class="co"># Add labels</span></span>
<span id="cb147-17"><a href="canonical-correlation-analysis-cca.html#cb147-17" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span>  <span class="co"># Add horizontal line</span></span>
<span id="cb147-18"><a href="canonical-correlation-analysis-cca.html#cb147-18" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="sc">+</span>  <span class="co"># Add vertical line</span></span>
<span id="cb147-19"><a href="canonical-correlation-analysis-cca.html#cb147-19" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb147-20"><a href="canonical-correlation-analysis-cca.html#cb147-20" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Biplot of Canonical Coefficients&quot;</span>, </span>
<span id="cb147-21"><a href="canonical-correlation-analysis-cca.html#cb147-21" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">&quot;First Canonical Variable&quot;</span>, </span>
<span id="cb147-22"><a href="canonical-correlation-analysis-cca.html#cb147-22" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Second Canonical Variable&quot;</span>) <span class="sc">+</span></span>
<span id="cb147-23"><a href="canonical-correlation-analysis-cca.html#cb147-23" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>)</span></code></pre></div>
<pre><code>## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
## ℹ Please use `linewidth` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.</code></pre>
<p><img src="_main_files/figure-html/cca-intro-example-vizualization-biplot-1.png" width="672" /></p>
<p><strong>Interpretation:</strong></p>
<ul>
<li><strong>Arrows represent original variables</strong> and their influence on canonical variables.<br />
</li>
<li><strong>Longer arrows</strong> indicate variables that contribute more to the canonical correlation.<br />
</li>
<li>Variables <strong>pointing in the same direction</strong> are <strong>highly correlated</strong>.</li>
</ul>
<hr />
</div>
<div id="canonical-correlation-bar-plot" class="section level5 hasAnchor" number="7.2.2.2.3">
<h5><span class="header-section-number">7.2.2.2.3</span> Canonical Correlation Bar Plot<a href="canonical-correlation-analysis-cca.html#canonical-correlation-bar-plot" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>A simple <strong>bar plot</strong> can be used to visualize the strength of each canonical correlation.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="canonical-correlation-analysis-cca.html#cb149-1" tabindex="-1"></a><span class="co"># Create bar plot of canonical correlations</span></span>
<span id="cb149-2"><a href="canonical-correlation-analysis-cca.html#cb149-2" tabindex="-1"></a><span class="fu">barplot</span>(cca_result<span class="sc">$</span>cor, </span>
<span id="cb149-3"><a href="canonical-correlation-analysis-cca.html#cb149-3" tabindex="-1"></a>        <span class="at">names.arg =</span> <span class="fu">paste</span>(<span class="st">&quot;Canonical Pair&quot;</span>, <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(cca_result<span class="sc">$</span>cor)), </span>
<span id="cb149-4"><a href="canonical-correlation-analysis-cca.html#cb149-4" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">&quot;steelblue&quot;</span>, </span>
<span id="cb149-5"><a href="canonical-correlation-analysis-cca.html#cb149-5" tabindex="-1"></a>        <span class="at">main =</span> <span class="st">&quot;Canonical Correlations&quot;</span>,</span>
<span id="cb149-6"><a href="canonical-correlation-analysis-cca.html#cb149-6" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">&quot;Correlation&quot;</span>,</span>
<span id="cb149-7"><a href="canonical-correlation-analysis-cca.html#cb149-7" tabindex="-1"></a>        <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/cca-intro-example-vizualization-barplot-1.png" width="672" /></p>
<p><strong>Interpretation:</strong></p>
<ul>
<li>High correlation values suggest a <strong>strong relationship</strong> between the two datasets.<br />
</li>
<li>If <strong>only the first few pairs</strong> have high correlations, then only those are meaningful.</li>
</ul>
<hr />
</div>
<div id="summary-of-visualizations" class="section level5 hasAnchor" number="7.2.2.2.4">
<h5><span class="header-section-number">7.2.2.2.4</span> <strong>Summary of Visualizations</strong><a href="canonical-correlation-analysis-cca.html#summary-of-visualizations" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li><strong>Scatter plot</strong> → Shows correlation between the first pair of canonical variables.<br />
</li>
<li><strong>Biplot</strong> → Shows how the original variables influence the canonical variables.<br />
</li>
<li><strong>Bar plot</strong> → Displays the strength of canonical correlations.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="canonical-directions-estimation" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Canonical Directions Estimation<a href="canonical-correlation-analysis-cca.html#canonical-directions-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="problem-definition-with-random-variables" class="section level3 hasAnchor" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Problem Definition with Random Variables<a href="canonical-correlation-analysis-cca.html#problem-definition-with-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(\mathbf{x} \in \mathbb{R}^{p}\)</span> and <span class="math inline">\(\mathbf{y} \in \mathbb{R}^{q}\)</span> be two sets of <strong>random variables</strong> with <strong>zero mean</strong> and the following covariance matrices:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{XX} = \mathbb{E}[\mathbf{x} \mathbf{x}&#39;] \quad \text{(Covariance of \( \mathbf{x} \))}
\]</span></p>
<p><span class="math display">\[
\mathbf{\Sigma}_{YY} = \mathbb{E}[\mathbf{y} \mathbf{y}&#39;] \quad \text{(Covariance of \( \mathbf{y} \))}
\]</span></p>
<p><span class="math display">\[
\mathbf{\Sigma}_{XY} = \mathbb{C}[\mathbf{x},  \mathbf{y}] \quad \text{(Cross-covariance between \( \mathbf{x} \) and \( \mathbf{y} \))}
\]</span></p>
<p>We seek <strong>canonical directions</strong> <span class="math inline">\(\mathbf{a} \in \mathbb{R}^{p}\)</span> and <span class="math inline">\(\mathbf{b} \in \mathbb{R}^{q}\)</span> such that the transformed random variables:</p>
<p><span class="math display">\[
U = \mathbf{a}&#39; \mathbf{x}, \quad V = \mathbf{b}&#39; \mathbf{y}
\]</span></p>
<p>are maximally correlated.</p>
<hr />
</div>
<div id="canonical-correlation-maximization-problem" class="section level3 hasAnchor" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Canonical Correlation Maximization Problem<a href="canonical-correlation-analysis-cca.html#canonical-correlation-maximization-problem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Mathematically, we solve:</p>
<p><span class="math display">\[
\max_{\mathbf{a}, \mathbf{b}} \quad \frac{\mathbb{C}[U, V]}{\sqrt{\mathbb{V}[U] \mathbb{V}[V]}}.
\]</span></p>
<p>Expanding in terms of covariances:</p>
<p><span class="math display">\[
\max_{\mathbf{a}, \mathbf{b}} \quad \frac{\mathbf{a}&#39; \mathbf{\Sigma}_{XY} \mathbf{b}}{\sqrt{\mathbf{a}&#39; \mathbf{\Sigma}_{XX} \mathbf{a} \cdot \mathbf{b}&#39; \mathbf{\Sigma}_{YY} \mathbf{b}}}.
\]</span></p>
<p>To ensure identifiability, we impose the normalization constraints:</p>
<p><span class="math display">\[
\mathbf{a}&#39; \mathbf{\Sigma}_{XX} \mathbf{a} = 1, \quad \mathbf{b}&#39; \mathbf{\Sigma}_{YY} \mathbf{b} = 1.
\]</span></p>
<p>This normalization ensures that the denominator is fixed at 1, so the objective function measures a valid correlation.</p>
<hr />
</div>
<div id="solving-for-the-canonical-directions-using-lagrange-multipliers" class="section level3 hasAnchor" number="7.3.3">
<h3><span class="header-section-number">7.3.3</span> Solving for the Canonical Directions Using Lagrange Multipliers<a href="canonical-correlation-analysis-cca.html#solving-for-the-canonical-directions-using-lagrange-multipliers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We introduce <strong>Lagrange multipliers</strong> <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\mu\)</span> and define the <strong>Lagrangian function</strong>:</p>
<p><span class="math display">\[
\mathcal{L}(\mathbf{a}, \mathbf{b}, \lambda, \mu) = \mathbf{a}&#39; \mathbf{\Sigma}_{XY} \mathbf{b} - \frac{\lambda}{2} (\mathbf{a}&#39; \mathbf{\Sigma}_{XX} \mathbf{a} - 1) - \frac{\mu}{2} (\mathbf{b}&#39; \mathbf{\Sigma}_{YY} \mathbf{b} - 1).
\]</span></p>
<div id="first-order-conditions" class="section level4 hasAnchor" number="7.3.3.1">
<h4><span class="header-section-number">7.3.3.1</span> First-order conditions<a href="canonical-correlation-analysis-cca.html#first-order-conditions" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Taking the derivative with respect to <span class="math inline">\(\mathbf{a}\)</span> and setting it to zero:</p>
<p><span class="math display">\[
\frac{\partial \mathcal{L}}{\partial \mathbf{a}} = \mathbf{\Sigma}_{XY} \mathbf{b} - \lambda \mathbf{\Sigma}_{XX} \mathbf{a} = 0.
\]</span></p>
<p><span class="math display">\[
\mathbf{\Sigma}_{XY} \mathbf{b} = \lambda \mathbf{\Sigma}_{XX} \mathbf{a}.
\]</span></p>
<p>Similarly, differentiating with respect to <span class="math inline">\(\mathbf{b}\)</span> and setting it to zero:</p>
<p><span class="math display">\[
\frac{\partial \mathcal{L}}{\partial \mathbf{b}} = \mathbf{\Sigma}_{YX} \mathbf{a} - \mu \mathbf{\Sigma}_{YY} \mathbf{b} = 0.
\]</span></p>
<p><span class="math display">\[
\mathbf{\Sigma}_{YX} \mathbf{a} = \mu \mathbf{\Sigma}_{YY} \mathbf{b}.
\]</span></p>
</div>
<div id="reformulation-as-a-generalized-eigenvalue-problem" class="section level4 hasAnchor" number="7.3.3.2">
<h4><span class="header-section-number">7.3.3.2</span> Reformulation as a Generalized Eigenvalue Problem<a href="canonical-correlation-analysis-cca.html#reformulation-as-a-generalized-eigenvalue-problem" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Multiplying the first equation on the left by <span class="math inline">\(\mathbf{\Sigma}_{YX}\)</span> gives:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{YX} \mathbf{\Sigma}_{XY} \mathbf{b} = \lambda \mathbf{\Sigma}_{YX} \mathbf{\Sigma}_{XX} \mathbf{a}.
\]</span></p>
<p>Substituting <span class="math inline">\(\mathbf{\Sigma}_{YX} \mathbf{a} = \mu \mathbf{\Sigma}_{YY} \mathbf{b}\)</span>:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{YX} \mathbf{\Sigma}_{XY} \mathbf{b} = \lambda \mu \mathbf{\Sigma}_{YY} \mathbf{b}.
\]</span></p>
<p>Similarly, multiplying the second equation on the left by <span class="math inline">\(\mathbf{\Sigma}_{XY}\)</span>:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{XY} \mathbf{\Sigma}_{YX} \mathbf{a} = \lambda \mu \mathbf{\Sigma}_{XX} \mathbf{a}.
\]</span></p>
<p>Thus, the canonical directions are found by solving the <strong>generalized eigenvalue problems</strong>:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} \mathbf{\Sigma}_{YY}^{-1} \mathbf{\Sigma}_{YX} \mathbf{a} = \lambda \mu \mathbf{a}.
\]</span></p>
<p><span class="math display">\[
\mathbf{\Sigma}_{YY}^{-1} \mathbf{\Sigma}_{YX} \mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} \mathbf{b} = \lambda \mu \mathbf{b}.
\]</span></p>
<hr />
</div>
</div>
<div id="showing-that-the-matrices-have-the-same-eigenvalues" class="section level3 hasAnchor" number="7.3.4">
<h3><span class="header-section-number">7.3.4</span> Showing That the Matrices Have the Same Eigenvalues<a href="canonical-correlation-analysis-cca.html#showing-that-the-matrices-have-the-same-eigenvalues" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Define:</p>
<p><span class="math display">\[
\mathbf{M} = \mathbf{\Sigma}_{YY}^{-1} \mathbf{\Sigma}_{YX}, \quad \mathbf{N} = \mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY}.
\]</span></p>
<p>Then we rewrite:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{YY}^{-1} \mathbf{\Sigma}_{YX} \mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} = \mathbf{M} \mathbf{N},
\]</span></p>
<p><span class="math display">\[
\mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} \mathbf{\Sigma}_{YY}^{-1} \mathbf{\Sigma}_{YX} = \mathbf{N} \mathbf{M}.
\]</span></p>
<p>To show that <span class="math inline">\(\mathbf{M} \mathbf{N}\)</span> and <span class="math inline">\(\mathbf{N} \mathbf{M}\)</span> have the <strong>same eigenvalues</strong>, consider the eigenvalue equation:</p>
<p><span class="math display">\[
\mathbf{M} \mathbf{N} \mathbf{v} = \lambda \mathbf{v}.
\]</span></p>
<p>Multiplying both sides by <span class="math inline">\(\mathbf{N}\)</span>:</p>
<p><span class="math display">\[
\mathbf{N} \mathbf{M} \mathbf{N} \mathbf{v} = \lambda \mathbf{N} \mathbf{v}.
\]</span></p>
<p>Defining <span class="math inline">\(\mathbf{w} = \mathbf{N} \mathbf{v}\)</span>, we obtain:</p>
<p><span class="math display">\[
\mathbf{N} \mathbf{M} \mathbf{w} = \lambda \mathbf{w}.
\]</span></p>
<p>Thus, every eigenvalue of <span class="math inline">\(\mathbf{M} \mathbf{N}\)</span> is also an eigenvalue of <span class="math inline">\(\mathbf{N} \mathbf{M}\)</span>, which proves that these two matrices have the <strong>same eigenvalues</strong>.</p>
<hr />
</div>
<div id="showing-that-the-largest-eigenvalue-maximizes-the-objective-function" class="section level3 hasAnchor" number="7.3.5">
<h3><span class="header-section-number">7.3.5</span> Showing That the Largest Eigenvalue Maximizes the Objective Function<a href="canonical-correlation-analysis-cca.html#showing-that-the-largest-eigenvalue-maximizes-the-objective-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For the estimated canonical directions <span class="math inline">\(\mathbf{a}_1, \mathbf{b}_1\)</span>, the <strong>value of the objective function</strong> is:</p>
<p><span class="math display">\[
\rho_1 = \frac{\mathbf{a}_1&#39; \mathbf{\Sigma}_{XY} \mathbf{b}_1}{\sqrt{\mathbf{a}_1&#39; \mathbf{\Sigma}_{XX} \mathbf{a}_1 \cdot \mathbf{b}_1&#39; \mathbf{\Sigma}_{YY} \mathbf{b}_1}}.
\]</span></p>
<p>Since the eigenvectors of:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} \mathbf{\Sigma}_{YY}^{-1} \mathbf{\Sigma}_{YX}
\]</span></p>
<p>are sorted in decreasing order of eigenvalues, the first eigenvalue corresponds to the maximum value of <span class="math inline">\(\rho\)</span>. This justifies why the <strong>largest eigenvalue</strong> gives the <strong>first canonical correlation</strong>, which achieves the <strong>maximum correlation</strong>.</p>
<hr />
</div>
<div id="conclusion-3" class="section level3 hasAnchor" number="7.3.6">
<h3><span class="header-section-number">7.3.6</span> Conclusion<a href="canonical-correlation-analysis-cca.html#conclusion-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><strong>CCA maximization leads to a generalized eigenvalue problem</strong>.<br />
</li>
<li><strong>The two matrices involved have the same eigenvalues</strong>, ensuring consistency.<br />
</li>
<li><strong>The largest eigenvalue corresponds to the maximum canonical correlation</strong>, justifying why the eigenvalue problem provides the optimal canonical directions.</li>
</ol>
<hr />
</div>
</div>
<div id="hd-cca" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> HD CCA<a href="canonical-correlation-analysis-cca.html#hd-cca" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When <span class="math inline">\(p \gg n\)</span> or <span class="math inline">\(q \gg n\)</span>, the covariance matrices <span class="math inline">\(\mathbf{\Sigma}_{XX}\)</span> and <span class="math inline">\(\mathbf{\Sigma}_{YY}\)</span> are <strong>singular</strong> (non-invertible). This makes standard <strong>Canonical Correlation Analysis (CCA)</strong> infeasible because it relies on inverting these matrices.</p>
<p>To address this issue, <strong>high-dimensional CCA methods</strong> have been developed. Below are the most effective alternatives:</p>
<hr />
<div id="regularized-canonical-correlation-analysis-ridge-cca" class="section level3 hasAnchor" number="7.4.1">
<h3><span class="header-section-number">7.4.1</span> Regularized Canonical Correlation Analysis (Ridge CCA)<a href="canonical-correlation-analysis-cca.html#regularized-canonical-correlation-analysis-ridge-cca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="idea" class="section level4 hasAnchor" number="7.4.1.1">
<h4><span class="header-section-number">7.4.1.1</span> Idea<a href="canonical-correlation-analysis-cca.html#idea" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Instead of solving the standard CCA problem:</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{XX}^{-1} \mathbf{\Sigma}_{XY} \mathbf{\Sigma}_{YY}^{-1} \mathbf{\Sigma}_{YX} \mathbf{a} = \lambda \mathbf{a},
\]</span></p>
<p>add a <strong>ridge regularization</strong> term:</p>
<p><span class="math display">\[
(\mathbf{\Sigma}_{XX} + \lambda \mathbf{I})^{-1} \mathbf{\Sigma}_{XY} (\mathbf{\Sigma}_{YY} + \lambda \mathbf{I})^{-1} \mathbf{\Sigma}_{YX} \mathbf{a} = \lambda \mathbf{a}.
\]</span></p>
</div>
<div id="advantages" class="section level4 hasAnchor" number="7.4.1.2">
<h4><span class="header-section-number">7.4.1.2</span> Advantages<a href="canonical-correlation-analysis-cca.html#advantages" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Avoids singularity by <strong>shrinking</strong> the covariance matrices.</li>
<li>Works well when <span class="math inline">\(p, q \gg n\)</span>.</li>
<li>Can be solved efficiently using <strong>Cholesky decomposition</strong>.</li>
</ul>
</div>
<div id="computational-complexity" class="section level4 hasAnchor" number="7.4.1.3">
<h4><span class="header-section-number">7.4.1.3</span> Computational Complexity<a href="canonical-correlation-analysis-cca.html#computational-complexity" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><span class="math inline">\(O(p^2 n)\)</span> if using Woodbury identity for inversion.<br />
</li>
<li>Faster than classical CCA for large <span class="math inline">\(p, q\)</span>.</li>
</ul>
<hr />
</div>
</div>
<div id="sparse-canonical-correlation-analysis-sparse-cca" class="section level3 hasAnchor" number="7.4.2">
<h3><span class="header-section-number">7.4.2</span> Sparse Canonical Correlation Analysis (Sparse CCA)**<a href="canonical-correlation-analysis-cca.html#sparse-canonical-correlation-analysis-sparse-cca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="idea-1" class="section level4 hasAnchor" number="7.4.2.1">
<h4><span class="header-section-number">7.4.2.1</span> Idea<a href="canonical-correlation-analysis-cca.html#idea-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Instead of using <strong>all variables</strong>, enforce sparsity in <span class="math inline">\(\mathbf{a}\)</span> and <span class="math inline">\(\mathbf{b}\)</span> by solving:</p>
<p><span class="math display">\[
\max_{\mathbf{a}, \mathbf{b}} \quad \mathbf{a}&#39; \mathbf{\Sigma}_{XY} \mathbf{b} \quad \text{s.t.} \quad \|\mathbf{a}\|_1 \leq c_1, \quad \|\mathbf{b}\|_1 \leq c_2.
\]</span></p>
<p>where <span class="math inline">\(\|\cdot\|_1\)</span> is the <strong>L1 norm</strong> (sum of absolute values), enforcing sparsity.</p>
</div>
<div id="advantages-1" class="section level4 hasAnchor" number="7.4.2.2">
<h4><span class="header-section-number">7.4.2.2</span> Advantages<a href="canonical-correlation-analysis-cca.html#advantages-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Selects <strong>only the most relevant variables</strong>.</li>
<li>Reduces overfitting.</li>
<li>Works well when <span class="math inline">\(p, q \gg n\)</span>.</li>
</ul>
</div>
<div id="computational-complexity-1" class="section level4 hasAnchor" number="7.4.2.3">
<h4><span class="header-section-number">7.4.2.3</span> Computational Complexity<a href="canonical-correlation-analysis-cca.html#computational-complexity-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Uses <strong>LASSO-like optimization</strong> (<span class="math inline">\(O(n p)\)</span>), making it efficient for large <span class="math inline">\(p, q\)</span>.</li>
</ul>
<hr />
</div>
</div>
<div id="low-rank-approximation-cca-randomized-svd-approach" class="section level3 hasAnchor" number="7.4.3">
<h3><span class="header-section-number">7.4.3</span> Low-Rank Approximation CCA (Randomized SVD Approach)<a href="canonical-correlation-analysis-cca.html#low-rank-approximation-cca-randomized-svd-approach" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="idea-2" class="section level4 hasAnchor" number="7.4.3.1">
<h4><span class="header-section-number">7.4.3.1</span> Idea<a href="canonical-correlation-analysis-cca.html#idea-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Instead of computing full covariance matrices, <strong>compress</strong> the data via a low-rank approximation:</p>
<ol style="list-style-type: decimal">
<li><p>Compute <strong>randomized SVD</strong> of <span class="math inline">\(\mathbf{X}\)</span> and <span class="math inline">\(\mathbf{Y}\)</span>:</p>
<p><span class="math display">\[
\mathbf{X} \approx \mathbf{U}_X \mathbf{\Sigma}_X \mathbf{V}_X&#39;
\]</span></p>
<p><span class="math display">\[
\mathbf{Y} \approx \mathbf{U}_Y \mathbf{\Sigma}_Y \mathbf{V}_Y&#39;
\]</span></p></li>
<li><p>Perform CCA on <strong>reduced-dimension data</strong> <span class="math inline">\(\mathbf{U}_X\)</span> and <span class="math inline">\(\mathbf{U}_Y\)</span>.</p></li>
</ol>
</div>
<div id="advantages-2" class="section level4 hasAnchor" number="7.4.3.2">
<h4><span class="header-section-number">7.4.3.2</span> Advantages<a href="canonical-correlation-analysis-cca.html#advantages-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Reduces dimensionality <strong>before</strong> computing canonical directions.</li>
<li>Works well when <span class="math inline">\(p, q \gg n\)</span>.</li>
<li>Computationally <strong>efficient</strong>.</li>
</ul>
</div>
<div id="computational-complexity-2" class="section level4 hasAnchor" number="7.4.3.3">
<h4><span class="header-section-number">7.4.3.3</span> Computational Complexity<a href="canonical-correlation-analysis-cca.html#computational-complexity-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><span class="math inline">\(O(n^2 p)\)</span> instead of <span class="math inline">\(O(p^3)\)</span>.</li>
</ul>
<hr />
</div>
</div>
<div id="factor-model-based-cca" class="section level3 hasAnchor" number="7.4.4">
<h3><span class="header-section-number">7.4.4</span> Factor Model-Based CCA<a href="canonical-correlation-analysis-cca.html#factor-model-based-cca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="idea-3" class="section level4 hasAnchor" number="7.4.4.1">
<h4><span class="header-section-number">7.4.4.1</span> Idea<a href="canonical-correlation-analysis-cca.html#idea-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Instead of estimating full covariance matrices, assume that <strong>data follows a factor model</strong>:</p>
<p><span class="math display">\[
\mathbf{X} = \mathbf{\Lambda}_X \mathbf{F} + \mathbf{\epsilon}_X
\]</span></p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{\Lambda}_Y \mathbf{F} + \mathbf{\epsilon}_Y
\]</span></p>
<p>where:
- <span class="math inline">\(\mathbf{F}\)</span> is a <strong>low-dimensional latent factor</strong>.
- <span class="math inline">\(\mathbf{\Lambda}_X\)</span> and <span class="math inline">\(\mathbf{\Lambda}_Y\)</span> are <strong>factor loadings</strong>.</p>
<p>Solve CCA on <strong>factor scores</strong> instead of raw data.</p>
</div>
<div id="advantages-3" class="section level4 hasAnchor" number="7.4.4.2">
<h4><span class="header-section-number">7.4.4.2</span> Advantages<a href="canonical-correlation-analysis-cca.html#advantages-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Works well when <span class="math inline">\(p, q \gg n\)</span>.</li>
<li>Reduces dimensionality by modeling <strong>latent structure</strong>.</li>
</ul>
</div>
<div id="computational-complexity-3" class="section level4 hasAnchor" number="7.4.4.3">
<h4><span class="header-section-number">7.4.4.3</span> Computational Complexity<a href="canonical-correlation-analysis-cca.html#computational-complexity-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><span class="math inline">\(O(n k^2)\)</span> if using PCA for factor estimation.</li>
</ul>
<hr />
</div>
</div>
<div id="comparison-of-methods-for-high-dimensional-cca" class="section level3 hasAnchor" number="7.4.5">
<h3><span class="header-section-number">7.4.5</span> Comparison of Methods for High-Dimensional CCA<a href="canonical-correlation-analysis-cca.html#comparison-of-methods-for-high-dimensional-cca" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table style="width:100%;">
<colgroup>
<col width="15%" />
<col width="24%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Method</strong></th>
<th><strong>Handles <span class="math inline">\(p, q \gg n\)</span>?</strong></th>
<th><strong>Avoids Inversion?</strong></th>
<th><strong>Captures Nonlinearity?</strong></th>
<th><strong>Computational Cost</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Ridge CCA</strong></td>
<td>✅ Yes</td>
<td>✅ Regularized</td>
<td>❌ No</td>
<td><span class="math inline">\(O(p^2 n)\)</span></td>
</tr>
<tr class="even">
<td><strong>Sparse CCA</strong></td>
<td>✅ Yes</td>
<td>✅ Sparse Estimation</td>
<td>❌ No</td>
<td><span class="math inline">\(O(n p)\)</span></td>
</tr>
<tr class="odd">
<td><strong>Low-Rank SVD CCA</strong></td>
<td>✅ Yes</td>
<td>✅ Uses SVD</td>
<td>❌ No</td>
<td><span class="math inline">\(O(n^2 p)\)</span></td>
</tr>
<tr class="even">
<td><strong>Factor Model CCA</strong></td>
<td>✅ Yes</td>
<td>✅ Uses PCA/FA</td>
<td>❌ No</td>
<td><span class="math inline">\(O(n k^2)\)</span></td>
</tr>
</tbody>
</table>
<hr />
</div>
</div>
<div id="conclusion-which-method-to-use" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> <strong>Conclusion: Which Method to Use?</strong><a href="canonical-correlation-analysis-cca.html#conclusion-which-method-to-use" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><strong>If you want a direct fix for singularity</strong> → Use <strong>Ridge CCA</strong>.<br />
</li>
<li><strong>If you suspect only a few variables matter</strong> → Use <strong>Sparse CCA</strong>.<br />
</li>
<li><strong>If you want a computationally efficient approach</strong> → Use <strong>Low-Rank SVD CCA</strong>.</li>
<li><strong>If data follows latent structures</strong> → Use <strong>Factor Model CCA</strong>.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="factor-analysis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
